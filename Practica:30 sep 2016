#despues del analisis gráfico se aplican pruebas de confirmación 
#generamos los valores ajustados, residuales y estandarizados
mochil$ajustados<-fitted(modmo)
mochil$residual<-residuals(modmo)
mochil$rstud<-rstudent(modmo)
#prueba de normalidad
install.packages("lmtest")
require(lmtest)
ks.test(mochil$rstud,"pnorm")
#se plantea una prueba de hipotesis y se espera un pvalue mayor a .05
#entonces no se rechaza la hipotesis nula y se acepta que hay normalidad
##la siguiente prueba es la homogeneidad de la varianzas y se usa la fn bptest
bptest(modmo,studentize = FALSE,data = mochil)
#tenemos un pvalue mayor a .05 por lo tanto pasa la prueva

#prueba de autocorrelacion
#se obtiene mediante la prueba de burbin watson
##### 2) el valor de Durbin Watson (rango aceptable 1.5 a 2.5) ->esto quiere 
##### decir que hay independencia entre los errores o que no hay correlación 
##### entre los mismos.

##### Hasta aquí podríamos confirmar que no hay correlación entre los residuos.

##### Con estas pruebas ya se confirma que tenemos un modelo con buen ajuste. Sin
##### embargo hay que revisar los casos atípicos {con unas pruebas que nos permite
##### confirmar o retractar lo que "vimos ayer" (más arriba cuando intentamos 
##### eliminar los datos que marcaban error de cooks)}... para revisar los atípicos
##### se usa la librería car

install.packages("car")
require (car)
outlierTest(modmo)

##### outlierTest: Muestra los casos atípicos dentro de mi modelo

##### Una vez que observamos los casos atípicos procedemos a conocer la influencia
##### de estos casos en el modelo. Para observar la influencia se utiliza la 
##### función "influence.measures()"

influ<- influence.measures(modmo)
##### Se genera un nuevo objeto
summary(influ)
##### Aquí se ve los casos que pueden tener mayor influencia en el modelo

##### En la primera columna se observan los casos más influyentes en este modelo
##### son 1, 2 y 10.

##### Las columnas que hacen referencia a dfb nos indican
# la influecia en los coeficientes del modelo
#las columnas que nos interesan son las de cook.d t hat
# la influencia de cook es la distancia y entre mas cercano a 1 quiere decir mayor influencia de la 
#observacion, en este caso la variable 10 tiene una mayor distancia, en esta medida si los valoresa son
#mayores a 1 hay certeza de que influyA
#en la columna de hat se asocia con las medidas de leverge que varian entre 0 y 1+}
#estre mas cercano a 1 mayor será la influencia
#ademas se hace un análisis gráfico con la fn influencepot() y requiere la libreria car
#el análisis se realiza con el tamaño de las circunferencias que arroja
#es decir al mayor circunferencia tiene mayor influencia

##grafica de distancias de cook
install.packages("faraway")
require(faraway)
dc<-cooks.distance(modmo)
etiqueta<-rownames(mochil)
halfnorm(dc,3,etiqueta)

